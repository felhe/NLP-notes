# Lecture 11: Data Generation and Noise Robustness

## Quality Control in Crowdsourcing
- qualification stage
- inject quiz questions
- require certain qualifications
- redundancy: multiple workers annotate same data

## Automatic Data Generation
### Distant Supervision
- use knowledge base to generate labels
- lookup words in knowledge base, e.g. find out if location or person name in Wikipedia
- problem: not all entities in knowledge base, disambiguation, spelling errors, spanning multiple words

### Weak Supervision
- write rules to generate labels
- example: find company names by legal form (e.g. GmbH, AG)
- problem: rules are incomplete, might be conflicting -> consensus method

### Use LLMs
- zero-shot learning: "Generate a positive/negative review about ..."
- few-shot learning: "Generate a positive/negative review like this one"
- problems: generated data is prompt dependent, lack of creativity

## Noise Robustness
- delaying memorization: noise gets learned in later epochs -> early stopping
- remove suspicious data or add clean data (expert annotation) with higher weights

### Types of Noise
- human error: attention slips, non-experts
- poor quality data: OCR errors, bad translations
- multiple labels: ambiguity, multiple correct answers
- irony

### Noise Simulation
- add noise to clean data
- problem: simulated noise is random, real noise is systematic
